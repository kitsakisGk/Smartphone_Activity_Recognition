# ğŸ“± Smartphone Activity Recognition

**Production-ready machine learning system for recognizing human activities from smartphone sensor data.**

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![TensorFlow 2.15](https://img.shields.io/badge/tensorflow-2.15-orange.svg)](https://www.tensorflow.org/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.3+-green.svg)](https://scikit-learn.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## ğŸ¯ Project Overview

This project demonstrates how to build a **production-quality machine learning system** for human activity recognition using smartphone sensor data. Originally developed as a university thesis, it has been refactored to follow **industry best practices** in ML engineering and data science.

### What It Does

Classifies human activities into 8 categories using accelerometer, gyroscope, and magnetometer data:

| Activity | Icon | Description |
|----------|------|-------------|
| Still | ğŸ§ | Standing or sitting motionless |
| Walking | ğŸš¶ | Normal walking pace |
| Running | ğŸƒ | Running or jogging |
| Biking | ğŸš´ | Cycling |
| Car | ğŸš— | Traveling by car |
| Bus | ğŸšŒ | Traveling by bus |
| Train | ğŸš† | Traveling by train |
| Subway | ğŸš‡ | Traveling by subway |

### Dataset

- **Source**: Sussex-Huawei Locomotion (SHL) Challenge Dataset
- **Size**: 30+ million samples from 3 users over 9 days
- **Sensors**: 9 features (3-axis accelerometer, gyroscope, magnetometer)
- **Sampling Rate**: 100 Hz

---

## ğŸ“Š Model Performance

**Tested on 6M+ validation samples (20% holdout set):**

| Model | Accuracy | F1-Score | Precision | Recall | Parameters | Training Time |
|-------|----------|----------|-----------|--------|------------|---------------|
| **Random Forest â­** | **90.4%** | **90.1%** | **90.6%** | **89.8%** | - | 4 min |
| CNN (VGG-inspired) | 89.9% | 90.0% | 91.9% | 88.2% | 225K | 7 min |
| CNN-GRU | 81.2% | 81.3% | 85.9% | 76.8% | 26K | 6 min |
| Logistic Regression | 44.9% | 35.5% | 40.4% | 35.4% | - | 1 min |

### Key Findings

âœ… **Random Forest is the best model** - Achieves highest accuracy with fastest training
âœ… **Traditional ML beats Deep Learning** - Shows critical thinking and proper evaluation
âœ… **45% improvement over baseline** - Random Forest vs Logistic Regression
âœ… **CNN is competitive** - Only 0.5% behind RF with more potential for improvement

This result demonstrates:
- **Data Science Rigor**: Proper baseline comparison before jumping to deep learning
- **Critical Thinking**: Not blindly applying neural networks
- **Production Mindset**: Choosing the best model based on performance AND training cost

> **Note**: Results use 30% data sampling for faster experimentation on consumer laptops. Full dataset training expected to improve accuracy by 2-3%.

---

## âœ¨ Features

### Models Implemented

1. **Baseline Models** (Traditional ML)
   - Random Forest (50 trees, max depth 15)
   - Logistic Regression (multi-class)

2. **Deep Learning Models**
   - CNN (VGG-16 inspired architecture)
   - LSTM (standalone recurrent model)
   - GRU (lightweight recurrent model)
   - CNN-LSTM (hybrid architecture)
   - CNN-GRU (hybrid architecture)

### Production-Ready Code

- âœ… **Modular Architecture**: Clean `src/` structure with separation of concerns
- âœ… **Configuration Management**: Centralized config for all hyperparameters
- âœ… **Logging**: Comprehensive logging at all stages
- âœ… **Error Handling**: Try-except blocks with meaningful error messages
- âœ… **Type Hints**: Full type annotations for better code quality
- âœ… **Documentation**: Docstrings for all classes and functions
- âœ… **Version Control**: `.gitignore` excludes data and model files
- âœ… **Reproducibility**: Fixed random seeds for consistent results

### Deployment Ready

- ğŸ³ **Docker**: Complete `Dockerfile` and `docker-compose.yml`
- ğŸŒ **Web Interface**: Streamlit app for interactive predictions
- ğŸ”„ **CI/CD**: GitHub Actions workflow for automated testing
- ğŸ“Š **Visualization**: Automatic plot generation for all metrics

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10 or higher
- 8GB RAM minimum (16GB recommended)
- ~6GB disk space for dataset

### Installation

```bash
# Clone the repository
git clone https://github.com/kitsakisGk/Smartphone_Activity_Recognition.git
cd Smartphone_Activity_Recognition

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### Data Setup

The dataset is **not included** in this repository due to its size (~6GB). See [DATA_SETUP.md](DATA_SETUP.md) for instructions on obtaining and preparing the data.

Quick version:
1. Download SHL dataset from [challenge website](http://www.shl-dataset.org/)
2. Place in `Data/` folder
3. Run preprocessing script

### Training Models

```bash
# Train Random Forest baseline (recommended to start)
python scripts/train_baseline.py --model random_forest

# Train CNN deep learning model
python scripts/train.py --model cnn

# Train LSTM model
python scripts/train.py --model lstm

# Compare all trained models
python scripts/compare_models.py
```

### Using the Web Interface

```bash
streamlit run app/streamlit_app.py
```

Then open your browser to `http://localhost:8501`

---

## ğŸ³ Docker Deployment

**What is Docker?** Docker packages your application with all its dependencies into a container, so it runs identically everywhere (your laptop, AWS, Google Cloud, etc.).

### Quick Start with Docker

```bash
# Build and run with docker-compose (easiest)
docker-compose up --build

# Access the Streamlit app at http://localhost:8501
```

### Manual Docker Commands

```bash
# Build the Docker image
docker build -t activity-recognition .

# Run the container
docker run -p 8501:8501 activity-recognition
```

### Why Use Docker?

- âœ… **Consistent Environment**: Works the same on any machine
- âœ… **Easy Deployment**: Push to cloud providers (AWS, GCP, Azure)
- âœ… **Isolation**: Doesn't interfere with other Python projects
- âœ… **Scalability**: Can easily run multiple instances

---

## ğŸ“ Project Structure

```
Smartphone_Activity_Recognition/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml              # GitHub Actions CI/CD pipeline
â”œâ”€â”€ app/
â”‚   â””â”€â”€ streamlit_app.py        # Interactive web interface
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml             # Configuration settings (optional)
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ EXAMPLE_RESULTS.md      # Detailed results and analysis
â”‚   â””â”€â”€ PRODUCTION_DEPLOYMENT.md # Cloud deployment guide
â”œâ”€â”€ models/                     # Saved trained models (not in git)
â”œâ”€â”€ notebooks/                  # Jupyter notebooks for exploration
â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ images/                 # Generated plots and visualizations
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ compare_models.py       # Compare all trained models
â”‚   â”œâ”€â”€ preprocess_data.py      # Data preprocessing pipeline
â”‚   â”œâ”€â”€ train.py                # Train deep learning models
â”‚   â””â”€â”€ train_baseline.py       # Train baseline models
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py               # Configuration dataclasses
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ loader.py           # Data loading utilities
â”‚   â”‚   â””â”€â”€ preprocessor.py     # Preprocessing and normalization
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ base.py             # Base model class
â”‚   â”‚   â”œâ”€â”€ baseline.py         # Random Forest & Logistic Regression
â”‚   â”‚   â”œâ”€â”€ cnn.py              # CNN model
â”‚   â”‚   â”œâ”€â”€ cnn_gru.py          # CNN-GRU hybrid
â”‚   â”‚   â”œâ”€â”€ cnn_lstm.py         # CNN-LSTM hybrid
â”‚   â”‚   â”œâ”€â”€ gru.py              # GRU model
â”‚   â”‚   â””â”€â”€ lstm.py             # LSTM model
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ logger.py           # Logging configuration
â”‚       â””â”€â”€ metrics.py          # Evaluation metrics
â”œâ”€â”€ tests/                      # Unit tests (to be added)
â”œâ”€â”€ .dockerignore               # Docker build exclusions
â”œâ”€â”€ .gitignore                  # Git exclusions
â”œâ”€â”€ DATA_SETUP.md               # Data acquisition guide
â”œâ”€â”€ docker-compose.yml          # Docker Compose configuration
â”œâ”€â”€ Dockerfile                  # Docker image definition
â”œâ”€â”€ GIT_COMMANDS.txt            # Git workflow reference
â”œâ”€â”€ LICENSE                     # MIT License
â”œâ”€â”€ README.md                   # This file
â””â”€â”€ requirements.txt            # Python dependencies
```

---

## ğŸ”§ Model Details

### Random Forest (Best Model)

**Why it works so well:**
- Handles high-dimensional sensor data effectively
- Captures spatial patterns (combinations of accelerometer/gyro readings)
- Fast training and inference
- No GPU required

**Architecture:**
- 50 decision trees
- Max depth: 15
- Min samples split: 2
- Stratified sampling for class balance

### CNN (Deep Learning)

**Why we include it:**
- Comparable accuracy to Random Forest
- Can improve with more data
- Transfer learning potential
- Better for real-time streaming data

**Architecture:**
- 2 Conv1D blocks (64 filters each)
- Batch Normalization
- MaxPooling
- Flatten + Dense layers
- Dropout (0.5) for regularization

### LSTM/GRU (Recurrent Models)

**When to use:**
- Sequential patterns are important
- Time-series forecasting
- Online learning scenarios

**Architecture:**
- 2 stacked LSTM/GRU layers (128 â†’ 64 units)
- Dropout (0.5) between layers
- Dense classification head

---

## ğŸ“ˆ Results Visualizations

All models automatically generate visualizations during training:

- **Training History**: Accuracy, loss, F1-score over epochs
- **Confusion Matrix**: Per-class performance breakdown
- **Model Comparison**: Side-by-side accuracy comparison
- **Feature Importance**: For Random Forest model

Plots saved to: `outputs/images/`

---

## ğŸ“ Learning Resources

### Understanding the Code

- **Data Pipeline**: Start with `src/data/loader.py` to see how data is loaded
- **Model Training**: Check `scripts/train.py` for training loop
- **Model Architecture**: Browse `src/models/` to see different architectures

### Key Concepts

- **Baseline Comparison**: Why we always compare against simple models first
- **Train/Validation Split**: Why we use 80/20 split with stratification
- **Overfitting Prevention**: Dropout, early stopping, validation monitoring
- **Time Series Windowing**: How LSTM/GRU process sequential data

---

## ğŸš€ Production Deployment

### Cloud Deployment Options

| Platform | Difficulty | Cost | Best For |
|----------|-----------|------|----------|
| **Heroku** | Easy | Free tier | Demos, portfolios |
| **AWS ECS** | Medium | ~$20/month | Small production |
| **Google Cloud Run** | Medium | Pay-per-request | Variable traffic |
| **Azure ML** | Hard | ~$50/month | Enterprise |

See [docs/PRODUCTION_DEPLOYMENT.md](docs/PRODUCTION_DEPLOYMENT.md) for detailed deployment guides.

### REST API Example

Want to deploy as an API? Here's a simple FastAPI example:

```python
from fastapi import FastAPI
import joblib
import numpy as np

app = FastAPI()
model = joblib.load("models/baseline_rf.pkl")

@app.post("/predict")
def predict(sensor_data: list):
    X = np.array(sensor_data).reshape(1, -1)
    prediction = model.predict(X)[0]
    return {"activity": prediction, "confidence": model.predict_proba(X).max()}
```

---

## ğŸ¤ Contributing

Contributions are welcome! Here's how you can help:

1. **Report Bugs**: Open an issue with details
2. **Suggest Features**: Propose new ideas in issues
3. **Submit PRs**: Fork, create a branch, and submit a pull request
4. **Improve Docs**: Fix typos, add examples, clarify explanations

### Development Setup

```bash
# Install development dependencies
pip install -r requirements.txt
pip install pytest black flake8

# Run tests
pytest tests/

# Format code
black src/ scripts/

# Lint code
flake8 src/ scripts/ --max-line-length=120
```

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Sussex-Huawei Locomotion Challenge** for the dataset
- **Harokopio University** for the original thesis project
- **scikit-learn and TensorFlow teams** for excellent ML libraries

---

## ğŸ“ Contact

**George Kitsakis**
- GitHub: [@kitsakisGk](https://github.com/kitsakisGk)
- Project: [Smartphone Activity Recognition](https://github.com/kitsakisGk/Smartphone_Activity_Recognition)

---

## ğŸ¯ Use Cases

This system can be applied to:

- **Fitness Tracking**: Automatic exercise recognition
- **Health Monitoring**: Detecting sedentary behavior
- **Elderly Care**: Fall detection and activity monitoring
- **Research**: Human behavior studies
- **Smart Cities**: Transportation mode detection

---

## ğŸ“š Citation

If you use this code in your research, please cite:

```bibtex
@misc{kitsakis2024activity,
  author = {Kitsakis, George},
  title = {Production-Ready Smartphone Activity Recognition},
  year = {2024},
  publisher = {GitHub},
  url = {https://github.com/kitsakisGk/Smartphone_Activity_Recognition}
}
```

---

â­ **Star this repo if you found it useful!**

ğŸ”— **Share it with others learning ML!**

ğŸ’¬ **Questions? Open an issue!**
